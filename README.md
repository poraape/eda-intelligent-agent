# ARCHITECT-X: Agente EDA com Gemini

Este projeto implementa um sistema de An√°lise Explorat√≥ria de Dados (EDA) inteligente, potencializado pela API Google Gemini. Ele funciona como um copiloto de an√°lise, permitindo o upload de arquivos CSV (ou ZIP) e transformando perguntas em linguagem natural em c√≥digo Python execut√°vel para gerar insights, tabelas e visualiza√ß√µes.

## ‚ú® Funcionalidades-Chave

- **Upload Flex√≠vel:** Aceita arquivos `.csv` e `.zip` de at√© 200MB.
- **Intelig√™ncia Artificial (Gemini):** Interpreta perguntas complexas em linguagem natural e gera o c√≥digo de an√°lise correspondente.
- **Pr√©-An√°lise Autom√°tica:** Ao carregar um arquivo, o agente exibe o esquema dos dados e sugere perguntas iniciais.
- **Code Interpreter:** Executa o c√≥digo gerado pelo Gemini em um ambiente seguro para produzir resultados (gr√°ficos, tabelas, texto).
- **L√≥gica Adaptativa:** Para datasets grandes (>100k linhas), o agente utiliza uma amostragem inteligente para manter a interface r√°pida.
- **Interface Minimalista:** UI limpa e profissional constru√≠da com Streamlit.

## üèõÔ∏è Arquitetura

O sistema utiliza uma arquitetura de **Agente LLM com Ferramentas (Code Interpreter)**.

- **Interface (Streamlit):** `main_app.py` √© respons√°vel pela UI e gerenciamento de estado da sess√£o.
- **N√∫cleo L√≥gico (Python + Gemini):** A classe `EDAAgentPro` em `src/agent.py` √© a fachada que:
    1.  Constr√≥i um prompt detalhado com o contexto dos dados.
    2.  Chama a API Gemini para gerar c√≥digo Python.
    3.  Executa o c√≥digo recebido de forma segura para obter o resultado.
- **Configura√ß√£o:** O arquivo `config.yaml` permite ajustar par√¢metros como modelo do LLM e limites de arquivo.
- **Seguran√ßa:** A chave da API √© gerenciada via vari√°veis de ambiente (`.env`) e secrets do ambiente de deploy.

## üõ†Ô∏è Stack Tecnol√≥gica

- **Linguagem:** Python 3.11+
- **LLM:** Google Gemini API (`gemini-1.5-flash`)
- **Interface:** Streamlit
- **An√°lise de Dados:** Pandas
- **Visualiza√ß√£o:** Plotly
- **Deployment:** Docker, Hugging Face Spaces

## üöÄ Como Executar Localmente

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone <URL_DO_REPOSITORIO>
    cd eda-intelligent-agent
    ```

2.  **Configure suas credenciais:**
    - Renomeie o arquivo `.env.example` para `.env`.
    - Abra o arquivo `.env` e insira sua chave da API Gemini.
    ```
    GEMINI_API_KEY="SUA_API_KEY_AQUI"
    ```

3.  **Crie e ative um ambiente virtual:**
    ```bash
    python -m venv venv
    source venv/bin/activate  # No Windows: venv\Scripts\activate
    ```

4.  **Instale as depend√™ncias:**
    ```bash
    pip install -r requirements.txt
    ```

5.  **Execute a aplica√ß√£o Streamlit:**
    ```bash
    streamlit run main_app.py
    ```
    A aplica√ß√£o estar√° dispon√≠vel em `http://localhost:8501`.

## üö¢ Deploy no Hugging Face Spaces

1.  Crie uma conta no [Hugging Face](https://huggingface.co/).
2.  Crie um novo "Space", selecionando "Streamlit" como o SDK e usando o template de Docker.
3.  Conecte o Space ao seu reposit√≥rio GitHub.
4.  V√° para as configura√ß√µes do Space, clique em "Secrets" e adicione um novo segredo:
    - **Name:** `GEMINI_API_KEY`
    - **Secret value:** Cole sua chave da API Gemini aqui.
5.  O Hugging Face ir√° construir e implantar a aplica√ß√£o. A chave ser√° lida automaticamente pelo `main_app.py`.

---
*Este projeto foi arquitetado e gerado pelo ARCHITECT-X.*